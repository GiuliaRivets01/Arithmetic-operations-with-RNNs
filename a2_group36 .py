# -*- coding: utf-8 -*-
"""A2_Group36.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a8D9S5U6lnf8bGZw4KvUmwk8DYyuSfa3

# Assignment A2 Group 36

# Authors: Evan Meltz, Giulia Rivetti, Chloé Tap

<div style="text-align: right">   </div>


Introduction to Deep Learning (2023) &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;| &nbsp;
-------|-------------------
**Assignment 2 - Recurrent Neural Networks** | <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/UniversiteitLeidenLogo.svg/1280px-UniversiteitLeidenLogo.svg.png" width="300">



# Introduction


The goal of this assignment is to learn how to use encoder-decoder recurrent neural networks (RNNs). Specifically we will be dealing with a sequence to sequence problem and try to build recurrent models that can learn the principles behind simple arithmetic operations (**integer addition, subtraction and multiplication.**).

<img src="https://i.ibb.co/5Ky5pbk/Screenshot-2023-11-10-at-07-51-21.png" alt="Screenshot-2023-11-10-at-07-51-21" border="0" width="500"></a>

In this assignment you will be working with three different kinds of models, based on input/output data modalities:
1. **Text-to-text**: given a text query containing two integers and an operand between them (+ or -) the model's output should be a sequence of integers that match the actual arithmetic result of this operation
2. **Image-to-text**: same as above, except the query is specified as a sequence of images containing individual digits and an operand.
3. **Text-to-image**: the query is specified in text format as in the text-to-text model, however the model's output should be a sequence of images corresponding to the correct result.


### Description**
Let us suppose that we want to develop a neural network that learns how to add or subtract
two integers that are at most two digits long. For example, given input strings of 5 characters: ‘81+24’ or
’41-89’ that consist of 2 two-digit long integers and an operand between them, the network should return a
sequence of 3 characters: ‘105 ’ or ’-48 ’ that represent the result of their respective queries. Additionally,
we want to build a model that generalizes well - if the network can extract the underlying principles behind
the ’+’ and ’-’ operands and associated operations, it should not need too many training examples to generate
valid answers to unseen queries. To represent such queries we need 13 unique characters: 10 for digits (0-9),
2 for the ’+’ and ’-’ operands and one for whitespaces ’ ’ used as padding.
The example above describes a text-to-text sequence mapping scenario. However, we can also use different
modalities of data to represent our queries or answers. For that purpose, the MNIST handwritten digit
dataset is going to be used again, however in a slightly different format. The functions below will be used to create our datasets.

---

*To work on this notebook you should create a copy of it.*
"""

# save files to drive (plots etc)
from google.colab import drive
drive.mount('/content/drive')

path_to_dir = '/content/drive/MyDrive/IDL files/'

"""# Function definitions for creating the datasets

First we need to create our datasets that are going to be used for training our models.

In order to create image queries of simple arithmetic operations such as '15+13' or '42-10' we need to create images of '+' and '-' signs using ***open-cv*** library. We will use these operand signs together with the MNIST dataset to represent the digits.
"""

# load all necessary modules
import tensorflow as tf
import matplotlib.pyplot as plt
import cv2
import numpy as np
import tensorflow as tf
import random
from sklearn.model_selection import train_test_split
import pandas as pd
from scipy.ndimage import rotate

from tensorflow.keras.layers import Dense, RNN, LSTM, Flatten, TimeDistributed, LSTMCell
from tensorflow.keras.layers import RepeatVector, Conv2D, SimpleRNN, GRU, Reshape, ConvLSTM2D, Conv2DTranspose

# Create plus/minus operand signs
def generate_images(number_of_images=50, sign='-'):

    blank_images = np.zeros([number_of_images, 28, 28])  # Dimensionality matches the size of MNIST images (28x28)
    x = np.random.randint(12, 16, (number_of_images, 2)) # Randomized x coordinates
    y1 = np.random.randint(6, 10, number_of_images)       # Randomized y coordinates
    y2 = np.random.randint(18, 22, number_of_images)     # -||-

    for i in range(number_of_images): # Generate n different images
        cv2.line(blank_images[i], (y1[i], x[i,0]), (y2[i], x[i, 1]), (255,0,0), 2, cv2.LINE_AA)     # Draw lines with randomized coordinates
        if sign == '+':
            cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA) # Draw lines with randomized coordinates
        if sign == '*':
            cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA)
            # Rotate 45 degrees
            blank_images[i] = rotate(blank_images[i], -50, reshape=False)
            cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA)
            blank_images[i] = rotate(blank_images[i], -50, reshape=False)
            cv2.line(blank_images[i], (x[i,0], y1[i]), (x[i, 1], y2[i]), (255,0,0), 2, cv2.LINE_AA)

    return blank_images

def show_generated(images, n=5):
    plt.figure(figsize=(2, 2))
    for i in range(n**2):
        plt.subplot(n, n, i+1)
        plt.axis('off')
        plt.imshow(images[i])
    plt.show()

show_generated(generate_images())
show_generated(generate_images(sign='+'))

def create_data(highest_integer, num_addends=2, operands=['+', '-']):
    """
    Creates the following data for all pairs of integers up to [1:highest integer][+/-][1:highest_integer]:

    @return:
    X_text: '151+ 21' -> text query of an arithmetic operation (7 )
    X_img : Stack of MNIST images corresponding to the query (7 x 28 x 28) -> sequence of 7 images of size 28x28
    y_text: ' 172' -> answer of the arithmetic text query
    y_img :  Stack of MNIST images corresponding to the answer (4 x 28 x 28)

    Images for digits are picked randomly from the whole MNIST dataset.
    """

    num_indices = [np.where(MNIST_labels==x) for x in range(10)]
    num_data = [MNIST_data[inds] for inds in num_indices]
    image_mapping = dict(zip(unique_characters[:10], num_data))
    image_mapping['-'] = generate_images()
    image_mapping['+'] = generate_images(sign='+')
    image_mapping['*'] = generate_images(sign='*')
    image_mapping[' '] = np.zeros([1, 28, 28])

    X_text, X_img, y_text, y_img = [], [], [], []

    for i in range(highest_integer + 1):      # First addend
        for j in range(highest_integer + 1):  # Second addend
            # for k in range(highest_integer + 1):  # Third addend
                # i_char = to_padded_chars(i, max_len=max_int_length) # convert integers to strings of constant length [20->' 20']
                # j_char = to_padded_chars(j, max_len=max_int_length, pad_right=True)
                # k_char = to_padded_chars(k, max_len=max_int_length, pad_right=True)

            for sign in operands: # Create all possible combinations of operands
                query_string = to_padded_chars(str(i) + sign + str(j), max_len=max_query_length, pad_right=True)
                query_image = []
                for n, char in enumerate(query_string):
                    image_set = image_mapping[char]
                    index = np.random.randint(0, len(image_set), 1)
                    query_image.append(image_set[index].squeeze())

                result = eval(query_string)
                result_string = to_padded_chars(result, max_len=max_answer_length, pad_right=True)
                result_image = []
                for n, char in enumerate(result_string):
                    image_set = image_mapping[char]
                    index = np.random.randint(0, len(image_set), 1)
                    result_image.append(image_set[index].squeeze())

                X_text.append(query_string)
                X_img.append(np.stack(query_image))
                y_text.append(result_string)
                y_img.append(np.stack(result_image))

    return np.stack(X_text), np.stack(X_img)/255., np.stack(y_text), np.stack(y_img)/255.

def to_padded_chars(integer, max_len=3, pad_right=False):
    """
    Returns a string of len()=max_len, containing the integer padded with ' ' on either right or left side
    """
    length = len(str(integer))
    padding = (max_len - length) * ' '
    if pad_right:
        return str(integer) + padding
    else:
        return padding + str(integer)

"""# Creating our data

The dataset consists of 20000 samples that (additions and subtractions between all 2-digit integers) and they have two kinds of inputs and label modalities:

  **X_text**: strings containing queries of length 7: ['  1+1  ', '11-18', ...]

  **X_image**: a stack of images representing a single query, dimensions: [5, 28, 28]

  **y_text**: strings containing answers of length 3: ['  2', '156']

  **y_image**: a stack of images that represents the answer to a query, dimensions: [3, 28, 28]
"""

# Illustrate the generated query/answer pairs

unique_characters = '0123456789+- '       # All unique characters that are used in the queries (13 in total: digits 0-9, 2 operands [+, -], and a space character ' '.)
highest_integer = 99                      # Highest value of integers contained in the queries (largest two digit number possible)

max_int_length = len(str(highest_integer))# Maximum number of characters in an integer = 2
max_query_length = max_int_length * 2 + 1 # Maximum length of the query string (consists of two integers and an operand [e.g. '22+10']) = 5
max_answer_length = 3    # Maximum length of the answer string (the longest resulting query string is ' 1-99'='-98') = 3

# Create the data (might take around a minute)
# Downloading data from mnist in keras
(MNIST_data, MNIST_labels), _ = tf.keras.datasets.mnist.load_data()
# Using previously defined function "create_data", makes up pairs of mnist data either added or subtracted
# Outputs text and image representations for input and output
X_text, X_img, y_text, y_img = create_data(highest_integer)
print(X_text.shape, X_img.shape, y_text.shape, y_img.shape)

# for X_text and y_text, (number of images,)
# for X_img and y_img, (number of images, number of digits/characters in image, x dim, y dim)
# for mnist, images are of shape (28,28)


## Display the samples that were created (visualize)
def display_sample(n):
    labels = ['X_img:', 'y_img:']
    for i, data in enumerate([X_img, y_img]):
        plt.subplot(1,2,i+1)
        # plt.set_figheight(15)
        plt.axis('off')
        plt.title(labels[i])
        plt.imshow(np.hstack(data[n]), cmap='gray')
    print('='*50, f'\nQuery #{n}\n\nX_text: "{X_text[n]}" = y_text: "{y_text[n]}"')
    plt.show()

# show 10 sample images
for _ in range(10):
    display_sample(np.random.randint(0, 10000, 1)[0])

# SHUFFLE DATA

# Create an array of indices and shuffle them
indices = np.arange(X_text.shape[0])
np.random.shuffle(indices)

# Use the shuffled indices to shuffle both data and labels
X_img = X_img[indices] # shuffled X_img
y_img = y_img[indices] # shuffled y_img
X_text = X_text[indices] #shuffled X_text
y_text = y_text[indices] # shuffled y_text

# check that samples are shuffled
def display_sample(n):
    labels = ['X_img:', 'y_img:']
    print("DIM: ", X_img.shape, y_img.shape)
    for i, data in enumerate([X_img, y_img]):
        plt.subplot(1,2,i+1)
        # plt.set_figheight(15)
        plt.axis('off')
        plt.title(labels[i])
        plt.imshow(np.hstack(data[n]), cmap='gray')
    print('='*50, f'\nQuery #{n}\n\nX_text: "{X_text[n]}" = y_text: "{y_text[n]}"')
    plt.show()

display_sample(np.random.randint(0, 10000, 1)[0])

"""## Helper functions

The functions below will help with input/output of the data.
"""

# One-hot encoding/decoding the text queries/answers so that they can be processed using RNNs
# You should use these functions to convert your strings and read out the output of your networks

def encode_labels(labels, max_len=3):
  ''' Converts text string such as '10+11' to encoded format - 5 arrays with a 1 in the position related to each character
   Encoded arrays are given as [0,0,0,0,0,0,0,0,0,0,0,0,0] corresponding to (0,1,2,3,4,5,6,7,8,9,+,-,_)
  '''
  # get number of input/output labels
  n = len(labels)
  # how long is the query? len('1+1') is 3
  length = len(labels[0])
  # len(unique_characters) = 13 (digits 0-9, + and -, and one space)
  # space included since we may be adding only two single digit numbers - spaces at the end

  # creates a map for the character encoding
  char_map = dict(zip(unique_characters, range(len(unique_characters))))

  # initialize them all as zeros
  # shape is: (number of images, number of characters in images - output, number of arrays of encoders)
  one_hot = np.zeros([n, length, len(unique_characters)])

  # add 1s for each encoded array where given character is stored
  for i, label in enumerate(labels):
      # initialize as 0s, subset of one_hot
      m = np.zeros([length, len(unique_characters)])
      # add a 1 to the position for which there is
      for j, char in enumerate(label):
          m[j, char_map[char]] = 1
      one_hot[i] = m

  return one_hot

def decode_labels(labels,max_len=3):
  '''Decode the encoded format back to text format, reverse of previous'''
  predictions = np.zeros(len(labels)).astype(str)
  characters = np.array([*unique_characters]).astype(str)
  # easy way to get each character in string format and their corresponding value (0-13)
  df = pd.DataFrame({'char':characters,'value':np.arange(0,len(characters))})
  for j, label in enumerate(labels):
    # for each array find the position where the maximum occurs (1 or close)
    pred = np.argmax(label, axis=1)
    # get all possible characters associated with these 'encoded' arrays
    values = [df['char'].loc[df['value']==x].values.item() for x in pred]
    # join them into a single string
    joined = ''.join(values)
    # append to predictions array (save)
    predictions[j] = joined
  return predictions

# test both functions to ensure they work
X_text_onehot = encode_labels(X_text)
y_text_onehot = encode_labels(y_text)
X_text_decode = decode_labels(X_text_onehot)
y_text_decode = decode_labels(y_text_onehot)

# encoded and decoded correctly?
print(X_text[100]==X_text_decode[100])
print(X_text[100])
print(X_text_onehot[100])

"""---
---

## I. Text-to-text RNN model

The following code showcases how Recurrent Neural Networks (RNNs) are built using Keras. Several new layers are going to be used:

1. LSTM
2. TimeDistributed
3. RepeatVector

The code cell below explains each of these new components.

<img src="https://i.ibb.co/NY7FFTc/Screenshot-2023-11-10-at-09-27-25.png" alt="Screenshot-2023-11-10-at-09-27-25" border="0" width="500"></a>

"""

def build_text2text_model(extra_layer=0):
  ''' Create a text2text model which takes encoded inputs and gives encoded outputs
      extra_layer = the number of LSTM layers added to the encoder of the model,
      to test if there are accuracy improvements - automatically set to 0
      i.e. only one LSTM layer in the encoder'''
  # We start by initializing a sequential model
  text2text = tf.keras.Sequential()
  if extra_layer == 0:
    # one input layer
    text2text.add(LSTM(256, input_shape=(None, len(unique_characters))))
  if extra_layer == 1:
    # two layers
    text2text.add(LSTM(256, return_sequences=True, input_shape=(None, len(unique_characters))))
    text2text.add(LSTM(256))
  if extra_layer == 2:
    # three layers
    text2text.add(LSTM(256, return_sequences=True, input_shape=(None, len(unique_characters))))
    text2text.add(LSTM(256, return_sequences=True))
    text2text.add(LSTM(256))
  if extra_layer == 3:
    # four layers
    text2text.add(LSTM(256, return_sequences=True, input_shape=(None, len(unique_characters))))
    text2text.add(LSTM(256, return_sequences=True))
    text2text.add(LSTM(256, return_sequences=True))
    text2text.add(LSTM(256))

  # As the decoder RNN's input, repeatedly provide with the last output of RNN for each time step. Repeat 3 times as that's the maximum length of the
  # output (e.g. '  1-99' = '-98') when using 2-digit integers in queries. In other words, the RNN will always produce 3 characters as its output.
  text2text.add(RepeatVector(max_answer_length))

  # By setting return_sequences to True, return not only the last output but all the outputs so far in the form of (num_samples, timesteps, output_dim).
  # This is necessary as TimeDistributed in the below expects the first dimension to be the timesteps.
  text2text.add(LSTM(256, return_sequences=True))

  # Apply a dense layer to the every temporal slice of an input. For each of step of the output sequence, decide which character should be chosen.
  text2text.add(TimeDistributed(Dense(len(unique_characters), activation='softmax')))

  # Next we compile the model using categorical crossentropy as our loss function.
  text2text.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
  text2text.summary()

  return text2text

## Your code (look at the assignment description for your tasks for text-to-text model):
# input text "encoded" data into the text2text model provided and change the splitting of this data between train and test
# a) 50-50
# b) 25-75
# c) 10-90
# Compare the results to true labels - visualisation
# put into dataframe both predicted and true labels (in text form - change to integers)
# find places where they don't match (.iloc[pred != true])
# visualize differences

batch_size = 128
epochs = 100

# vary train and test split
train_test_size = [0.5, 0.75, 0.9]
# index of train_test_size array: 0 = 50-50, 1 = 25-75, 2 = 10-90
i = 1

# split data into train and test sets
X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(X_text, y_text, test_size=train_test_size[i], random_state=42)

# check shapes
print(X_text_train.shape)
print(y_text_train.shape)

# One-hot encoding
X_text_train = encode_labels(X_text_train)
y_text_train = encode_labels(y_text_train)
X_text_test = encode_labels(X_text_test)
y_text_test = encode_labels(y_text_test)

# create model
model = build_text2text_model(extra_layer=0)

# train model
history = model.fit(X_text_train, y_text_train,
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1,
                    validation_data=(X_text_test, y_text_test))

# evaluate for test data
score = model.evaluate(X_text_test, y_text_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

# get predictions
y_text_pred = model.predict(X_text_test)

# Decode inputs and outputs (for visualisation)
X_text_test = decode_labels(X_text_test)
X_text_train = decode_labels(X_text_train)
y_text_train = decode_labels(y_text_train)
y_text_test = decode_labels(y_text_test)
y_text_pred = decode_labels(y_text_pred)

print("True labels: ", y_text_test)
print("Our output predictions: ", y_text_pred)

# Accuracy per epoch for training and test data

fig1,ax1=plt.subplots(figsize=(6.5,6.5))
ax1.plot(np.array(history.history['accuracy'])*100)
ax1.plot(np.array(history.history['val_accuracy'])*100)
ax1.set_title('RNN Model Accuracy for Text to text',fontweight='bold',fontsize=15)
ax1.grid(lw=0.2)
ax1.set_ylabel('Accuracy (%)',fontsize=13)
ax1.set_xlabel('Epoch number',fontsize=13)
ax1.set_yticks(np.arange(0,101,10))
ax1.set_xticks(np.arange(0,101,10))
ax1.legend(['training', 'test'], loc='upper left')
plt.show()
fig1.savefig(path_to_dir + 'text2text_accuracy_test'+str(train_test_size[i])+'.pdf')

"""**Train = 50%, Test = 50%**

Unshuffled
* Train accuracy: 0.9799
* Train loss: 0.0936
* Test accuracy: 0.9640
* Test loss: 0.1149

Shuffled
* Train loss: 0.0656
* Train accuracy: 0.9825
* Test loss: 0.0614
* Test accuracy: 0.9816

**Train = 25%, Test = 75%**

Unshuffled
* Train loss: 0.5778
* Train accuracy: 0.7977
* Test loss: 0.8297
* Test accuracy: 0.6690

Shuffled
* Train loss: 0.1643
* Train accuracy: 0.9711
* Test loss: 0.2326
* Test accuracy: 0.9312


**Train = 10%, Test = 90%**

Unshuffled
* Train loss: 1.1655
* Train accuracy: 0.5853
* Test loss: 1.3021
* Test accuracy: 0.5279

Shuffled
* Train loss: 0.6919
* Train accuracy: 0.7732
* Test loss: 1.0862
* Test accuracy: 0.6253
"""

# indices where there are empty predictions i.e. output is '-  ' or '   '
# ignore (as they cannot be converted to float values for visualization)
idx = np.where(y_text_pred == '-  ')
idx1 = np.where(y_text_pred == '   ')
all_idx = np.concatenate((idx,idx1),axis=1)
# checks where unlabelled data matches test data
mask = np.in1d(range(y_text_test.shape[0]), all_idx)
# convert to floats for plotting - only take the points where there is no unlabelled output
pred_float = y_text_pred[~mask].astype(float)
true_float = y_text_test[~mask].astype(float)

# take only those that don't match - i.e. incorrect predictions
mismatch = np.where(pred_float != true_float)
# filter accordingly
pred_wrong = pred_float[mismatch]
true_wrong = true_float[mismatch]

# find where the most extreme values occur - i.e. outside the range of (min(true),max(true))
high_idx = np.where(np.logical_or(pred_wrong > np.max(true_float), pred_wrong < np.min(true_float)))
# remove extreme values (outliers) - for ease of plotting
select = np.in1d(range(pred_wrong.shape[0]), high_idx)
pred_lim = pred_wrong[~select]
true_lim = true_wrong[~select]

# determine differences (for colorbar)
diffs_all = np.abs(true_wrong - pred_wrong)
diffs_lim = np.abs(true_lim - pred_lim)

# FULL PLOT: includes outliers
# make points with certain differences have colours for various ranges (or just an overall colorbar)
fig,ax = plt.subplots(figsize=(6.5,6.5))
# correct prediction line
ax.plot(np.arange(min(pred_lim),max(pred_lim)+1),np.arange(min(pred_lim),max(pred_lim)+1),color='k',lw=0.5,label='Correct prediction line')
# scatter points for true vs predicted
scatter = ax.scatter(true_wrong,pred_wrong,marker='o',s=10,c=diffs_all,cmap='Spectral')
ax.set_xlabel('True value',fontsize=13)
ax.set_ylabel('Predicted value',fontsize=13)
ax.set_title('Text-to-text model visualisation, train:test = %i:%i' %(100-100*train_test_size[i],train_test_size[i]*100),fontsize=13,fontweight='bold')
ax.grid(alpha=0.2)

# colour points based on the difference between true and predicted - add colorbar to illustrate what colours mean
cb = fig.colorbar(scatter,orientation='horizontal',location='bottom',ticks=np.arange(0,np.max(diffs_all)+1,100))
cb.set_label(label='Difference between true and predicted',fontsize=11)
plt.show()
fig.savefig(path_to_dir + 'text2text_visual_test' + str(train_test_size[i])+ '.pdf')



# LIMITS PLOT TO ONLY POINTS IN RANGE [MIN(TRUE),MAX(TRUE)]
# Similar to previous, but only
fig1,ax1 = plt.subplots(figsize=(6.5,6.5))
# correct prediction line
ax1.plot(np.arange(min(pred_lim),max(pred_lim)+1),np.arange(min(pred_lim),max(pred_lim)+1),color='k',lw=0.5,label='Correct prediction line')
# scatter points for true vs predicted
scatter1 = ax1.scatter(true_lim,pred_lim,marker='o',s=10,c=diffs_lim,cmap='Spectral')
ax1.set_xlabel('True value',fontsize=13)
ax1.set_ylabel('Predicted value',fontsize=13)
ax1.grid(alpha=0.2)
ax1.set_title('Text-to-text model visualisation, train:test = %i:%i' %(train_test_size[i]*100,100-100*train_test_size[i]),fontsize=13,fontweight='bold')

# colour points based on the difference between true and predicted - add colorbar to illustrate what colours mean
cb1 = fig1.colorbar(scatter1,orientation='horizontal',location='bottom',ticks=np.arange(0,np.max(diffs_lim)+1,10))
cb1.set_label(label='Difference between true and predicted',fontsize=11)
ax1.legend()
plt.show()
fig1.savefig(path_to_dir + 'text2text_visual_test_lim' + str(train_test_size[i])+ '.pdf')


# print some interesting information
print('Total number of test data points:', len(y_text_test))
print('Number of unlabelled test prediction outputs:', len(all_idx))
print('Fraction of incorrectly predicted values:', len(pred_wrong)/len(y_text_pred))
print('Number of predictions which supercede maximum of +/- 198 is', len(pred_wrong[high_idx]))
print('True labels for high range:', true_wrong[high_idx])
print('Predicted labels for high range:', pred_wrong[high_idx])
print('True vs predicted labels for large differences i.e. greater than +/- 20')
print(true_wrong[np.where(diffs_all>20)])
print(pred_wrong[np.where(diffs_all>20)])
print('Number of predictions that have small differences from true:', len(pred_wrong)-len(true_wrong[np.where(diffs_all>20)]))

"""### Adding more LSTM layers to text-to-text model


Adding 1 LSTM and test = 50%:
- Test loss: 0.01318932231515646
- Test accuracy: 0.9980000257492065

Adding 2 LSTM and test = 50%:
- Test loss: 0.03230324760079384
- Test accuracy: 0.9915000200271606

Adding 3 LSTM and test = 50%:
- Test loss: 0.3876280188560486
- Test accuracy: 0.8284000158309937

---
---

## II. Image to text RNN Model

Hint: There are two ways of building the encoder for such a model - again by using the regular LSTM cells (with flattened images as vectors) or recurrect convolutional layers [ConvLSTM2D](https://keras.io/api/layers/recurrent_layers/conv_lstm2d/).

The goal here is to use **X_img** as inputs and **y_text** as outputs.
"""

def build_image2text_model(input_shape, num_classes, extra_layer=0):
  ''' Create image to text model which takes flattened images and converts to encoded vectors
      Input_shape = shape of the flattened image (time_step, img_height*img_width)
      Num_classes = all possible characters that can come from encoded format (0-9,+,-,_)
      Extra_layer = added LSTM layers to encoder, set as 0 (can be increased later)'''
  # Initialize a sequential model
  image2text = tf.keras.Sequential()

  # "Encode" the image sequence using an RNN, producing an output of size 256.
  if extra_layer == 0:
    # one layer
    image2text.add(LSTM(256, input_shape=input_shape))
  elif extra_layer == 1:
    # two layers
    image2text.add(LSTM(256, return_sequences=True, input_shape=input_shape))
    image2text.add(LSTM(256))
  elif extra_layer == 2:
    # three layers
    image2text.add(LSTM(256, return_sequences=True, input_shape=input_shape))
    image2text.add(LSTM(256, return_sequences=True))
    image2text.add(LSTM(256))
  elif extra_layer == 3:
    # four layers
    image2text.add(LSTM(256, return_sequences=True, input_shape=input_shape))
    image2text.add(LSTM(256, return_sequences=True))
    image2text.add(LSTM(256, return_sequences=True))
    image2text.add(LSTM(256))

  # Repeat the encoded representation for the maximum answer length
  image2text.add(RepeatVector(max_answer_length))

  # Decoder RNN
  image2text.add(LSTM(256, return_sequences=True))

  # Apply a dense layer to each temporal slice of the output
  image2text.add(TimeDistributed(Dense(num_classes, activation='softmax')))

  # Compile the model using categorical crossentropy as the loss function
  image2text.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
  image2text.summary()

  return image2text

batch_size = 128
epochs = 100
i = 0
train_test_size = [0.5, 0.75, 0.9]

# Assuming X_img_train and y_img_train are your training data
X_img_train, X_img_test, y_text_train, y_text_test = train_test_split(X_img, y_text, test_size=train_test_size[i], random_state=42)

# Get the number of unique classes (characters) directly from the data
num_classes = len(unique_characters)

# One-hot encode the target data
y_text_train = encode_labels(y_text_train)
y_text_test = encode_labels(y_text_test)

# image shape
img_height, img_width = 28, 28
print(X_img_train.shape)

# Reshape input data to include a timestep dimension
# Reshape input data to have the appropriate dimensions for LSTM
X_img_train = X_img_train.reshape((X_img_train.shape[0], X_img_train.shape[1], -1))
X_img_test = X_img_test.reshape((X_img_test.shape[0], X_img_test.shape[1], -1))


# Update the input shape accordingly
#input_shape = (img_height * img_width, 1)
input_shape = (5, img_height * img_width)

#X_img_train = X_img_train.astype('float32')
#X_img_test = X_img_test.astype('float32')
#X_img_train /= 255
#X_img_test /= 255

# build model with given number of additional LSTM layers
model = build_image2text_model(input_shape, num_classes, extra_layer=1)
model.summary()

# fit the model using training data
history = model.fit(X_img_train, y_text_train,
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1,
                    validation_data=(X_img_test, y_text_test))

# Evaluate the model
score = model.evaluate(X_img_test, y_text_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

"""### Image to text accuracy after 100 epochs:

test-size = 50%:
- Test loss: 1.9118677377700806
- Test accuracy: 0.40006667375564575

test-size = 75%:
- Test loss: 1.8499771356582642
- Test accuracy: 0.3840889036655426

test-size = 90%:
- Test loss: 1.978256344795227
- Test accuracy: 0.3592222332954407

### Adding more LSTM layers to image-to-text model


Adding 1 LSTM and test = 50%:
- Test loss: 4.592964172363281
- Test accuracy: 0.5143666863441467

Adding 2 LSTM and test = 50%:
- Test loss: 3.8308968544006348
- Test accuracy: 0.5616333484649658

Adding 3 LSTM and test = 50%:
- Test loss: 2.784349203109741
- Test accuracy: 0.5946666598320007

---
---

## III. Text to image RNN Model

Hint: to make this model work really well you could use deconvolutional layers in your decoder (you might need to look up ***Conv2DTranspose*** layer). However, regular vector-based decoder will work as well.

The goal here is to use **X_text** as inputs and **y_img** as outputs.
"""

def build_text2image_model(extra_layer=0):
  ''' Create text to image model which takes encoded vectors as input and outputs grayscale images'''
  # Input layer for the text sequence
  text2image = tf.keras.Sequential()
  if extra_layer == 0:
    text2image.add(LSTM(256, return_sequences=False, input_shape=(None, len(unique_characters))))

  elif extra_layer == 1:
    text2image.add(LSTM(256, return_sequences=True, input_shape=(None, len(unique_characters))))
    text2image.add(LSTM(256))

  elif extra_layer == 2:
    text2image.add(LSTM(256, return_sequences=True, input_shape=(None, len(unique_characters))))
    text2image.add(LSTM(256, return_sequences=True))
    text2image.add(LSTM(256))

  elif extra_layer == 3:
    text2image.add(LSTM(256, return_sequences=True, input_shape=(None, len(unique_characters))))
    text2image.add(LSTM(256, return_sequences=True))
    text2image.add(LSTM(256, return_sequences=True))
    text2image.add(LSTM(256))

  # Repeat the encoded representation for each time step in the output sequence
  text2image.add(RepeatVector(max_answer_length))

  # Decoder RNN layer
  text2image.add(LSTM(256, return_sequences=True))

  # Apply a dense layer to each temporal slice of the input to generate image data
  text2image.add(TimeDistributed(Dense(28*28, activation='sigmoid')))

  # Reshape the output to the dimensions of an image
  text2image.add(Reshape((max_answer_length, 28, 28, 1)))

  text2image.add(TimeDistributed(Conv2DTranspose(64, (3, 3), activation='relu', padding='same')))
  text2image.add(TimeDistributed(Conv2DTranspose(32, (3, 3), activation='relu', padding='same')))
  text2image.add(TimeDistributed(Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')))


  # Compile the model using an appropriate loss function for image generation (e.g., mean squared error)
  text2image.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])
  text2image.summary()

  return text2image

# Text to Image

batch_size = 128
epochs = 100

# splits for train and test data
train_test_size = [0.5, 0.75, 0.9]
i = 0

# Assuming X_img_train and y_img_train are your training data
X_text_train, X_text_test, y_img_train, y_img_test = train_test_split(X_text, y_img, test_size=train_test_size[i], random_state=42)

# Encode text inputs
X_text_train = encode_labels(X_text_train)
X_text_test = encode_labels(X_text_test)

print("X_text_train shape: ", X_text_train.shape)
print("y_img_train shape: ", y_img_train.shape)

# build model
text2image = build_text2image_model(extra_layer=1)

# fit using training data
history = text2image.fit(X_text_train, y_img_train,
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1,
                    validation_data=(X_text_test, y_img_test))

# Evaluate the model
score = text2image.evaluate(X_text_test, y_img_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

# To evaluate the accuracy of the model, it is best to examine how the output images
# compare to the images associated with the text inputs used

generated_images = text2image.predict(X_text_test)

## Display the samples that were created
def display_sample(n):
    labels = ['y_img_test:', 'generated_img:']
    print("DIM: ", y_img_test.shape, generated_images.shape)
    for i, data in enumerate([y_img_test, generated_images]):
        plt.subplot(1,2,i+1)
        # plt.set_figheight(15)
        plt.axis('off')
        plt.title(labels[i])
        plt.imshow(np.hstack(data[n]), cmap='gray')
    #print('='*50, f'\nQuery #{n}\n\nX_text: "{X_text_test[n]}"')
    plt.show()

# show a random sample of images
for _ in range(10):
    display_sample(np.random.randint(0, 10000, 1)[0])

"""
---
---
---

# Part 2: Multiplication
The cell below will create the multiplication dataset used in this part of the assignment."""

# Illustrate the generated query/answer pairs

unique_characters = '0123456789* '       # All unique characters that are used in the queries (13 in total: digits 0-9, 2 operands [+, -], and a space character ' '.)
highest_integer = 99                      # Highest value of integers contained in the queries

max_int_length = len(str(highest_integer))# Maximum number of characters in an integer
max_query_length = max_int_length * 2 + 1 # Maximum length of the query string (consists of two integers and an operand [e.g. '22+10'])
max_answer_length = 5    # Maximum length of the answer string (the longest resulting query string is ' 1-99'='-98')

# Create the data (might take around a minute)
(MNIST_data, MNIST_labels), _ = tf.keras.datasets.mnist.load_data()
X_text, X_img, y_text, y_img = create_data(highest_integer, operands=['*'])
print(X_text.shape, X_img.shape, y_text.shape, y_img.shape)


## Display the samples that were created
def display_sample(n):
    labels = ['X_img:', 'y_img:']
    for i, data in enumerate([X_img, y_img]):
        plt.subplot(1,2,i+1)
        # plt.set_figheight(15)
        plt.axis('off')
        plt.title(labels[i])
        plt.imshow(np.hstack(data[n]), cmap='gray')
    print('='*50, f'\nQuery #{n}\n\nX_text: "{X_text[n]}" = y_text: "{y_text[n]}"')
    plt.show()

for _ in range(10):
    display_sample(np.random.randint(0, 10000, 1)[0])

# SHUFFLE DATA

# Create an array of indices and shuffle them
indices = np.arange(X_text.shape[0])
np.random.shuffle(indices)

# Use the shuffled indices to shuffle both data and labels
X_img = X_img[indices] # shuffled X_img
y_img = y_img[indices] # shuffled y_img
X_text = X_text[indices] #shuffled X_text
y_text = y_text[indices] # shuffled y_text

# need an encode and decode method
# should be the same as last task, just instead for outputs which can be max 5 digits
# i.e. max_len = 5

X_text_onehot = encode_labels(X_text,max_len=5)
y_text_onehot = encode_labels(y_text,max_len=5)
X_text_decode = decode_labels(X_text_onehot)
y_text_decode = decode_labels(y_text_onehot)

print(X_text_onehot.shape, y_text_onehot.shape)

"""In this section, we have reused the same models for text2text and image2text which have been defined in the addition/subtraction section. The only difference is the input data which comes from that defined for multiplication images shown above.

# I: Text to text model for multiplication
"""

# text2text for multiplication
batch_size = 128
epochs = 100

train_test_size = [0.5, 0.75, 0.9]
i = 0
X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(X_text, y_text, test_size=train_test_size[i], random_state=42)
print(X_text_train.shape)
print(y_text_train.shape)

# One-hot encoding
X_text_train = encode_labels(X_text_train)
y_text_train = encode_labels(y_text_train)
X_text_test = encode_labels(X_text_test)
y_text_test = encode_labels(y_text_test)

# use the previous model and build for multiplication
model = build_text2text_model(extra_layer=2)

history = model.fit(X_text_train, y_text_train,
                    batch_size=batch_size,
                    epochs=epochs,
                    verbose=1,
                    validation_data=(X_text_test, y_text_test))


score = model.evaluate(X_text_test, y_text_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

y_text_pred = model.predict(X_text_test)

# Decode
X_text_test = decode_labels(X_text_test)
X_text_train = decode_labels(X_text_train)
y_text_train = decode_labels(y_text_train)
y_text_test = decode_labels(y_text_test)
y_text_pred = decode_labels(y_text_pred)

print("True labels: ", y_text_test)
print("Our output predictions: ", y_text_pred)

"""Adding more LSTM layer

50-50 split
* 1 extra layer: 0.7548
* 2 extra layers: 0.7086
* 3 extra layers: 0.6691

25-75 split
* 1 extra layer: 0.6106
* 2 extra layers: 0.5849
* 3 extra layers: 0.5832

10-90 split
* 1 extra layer: 0.5284
* 2 extra layers: 0.5321
* 3 extra layers: 0.5354

# II: Image to text model for multiplication
"""

batch_size = 128
epochs = 100
train_test_size = [0.5, 0.75, 0.9]
i = 2

# Assuming X_img_train and y_img_train are your training data
X_img_train, X_img_test, y_text_train, y_text_test = train_test_split(X_img, y_text, test_size=train_test_size[i], random_state=42)


# One-hot encode the target data
num_classes = len(unique_characters)  # Get the number of unique classes directly from the data
y_text_train = encode_labels(y_text_train)
y_text_test = encode_labels(y_text_test)

img_height, img_width = 28, 28
print(X_img_train.shape)

# Reshape your input data to include a timestep dimension
# Reshape your input data to have the appropriate dimensions for LSTM
X_img_train = X_img_train.reshape((X_img_train.shape[0], X_img_train.shape[1], -1))
X_img_test = X_img_test.reshape((X_img_test.shape[0], X_img_test.shape[1], -1))
# Update the input shape accordingly
#input_shape = (img_height * img_width, 1)
input_shape = (5, 784)

#X_img_train = X_img_train.astype('float32')
#X_img_test = X_img_test.astype('float32')
#X_img_train /= 255
#X_img_test /= 255


model = build_image2text_model(input_shape, num_classes, extra_layer=3)

history = model.fit(X_img_train, y_text_train,
                     batch_size=batch_size,
                     epochs=epochs,
                     verbose=1,
                     validation_data=(X_img_test, y_text_test))

# Evaluate the model
score = model.evaluate(X_img_test, y_text_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

"""Adding more layer (image to text)

50-50
* 1 extra layer: 0.4774
* 2 extra layers: 0.5028
* 3 extra layers: 0.5119

25-75
* 1 extra layer: 0.4350
* 2 extra layers: 0.4466
* 3 extra layers: 0.4492

10-90
* 1 extra layer: 0.3877
* 2 extra layers: 0.3960
* 3 extra layers: 0.3959
"""